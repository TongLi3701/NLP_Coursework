{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVR+Sentence_embed_Bert_large+raw.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiWVNrSepufI",
        "colab_type": "text"
      },
      "source": [
        "# NLP Coursework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-5YiHHftBX",
        "colab_type": "text"
      },
      "source": [
        "## Dowdload and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuNdY9X-fSlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from scipy.stats.stats import pearsonr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A0Z6AWU37Gg",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w8HNiip39OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path):\n",
        "    \"\"\"\n",
        "    Read data from the data path.\n",
        "\n",
        "    Args: \n",
        "        path: the path of the dataset, normally in local folder.\n",
        "    \n",
        "    Returns:\n",
        "        Loaded raw dataset. \n",
        "    \"\"\"\n",
        "    with open(path) as dataset:\n",
        "        raw_data = dataset.readlines()\n",
        "\n",
        "    return raw_data\n",
        "\n",
        "\n",
        "# Define the path of the train dataset\n",
        "english_train_path = \"train.enzh.src\"\n",
        "chinese_train_path = \"train.enzh.mt\"   \n",
        "scores_train_path = \"train.enzh.scores\"\n",
        "# Define the path of the validatin dataset\n",
        "english_validation_path = \"dev.enzh.src\"\n",
        "chinese_validation_path = \"dev.enzh.mt\"   \n",
        "scores_validation_path = \"dev.enzh.scores\"\n",
        "# Define the path of the test dataset\n",
        "english_test_path = \"test.enzh.src\"\n",
        "chinese_test_path = \"test.enzh.mt\"\n",
        "\n",
        "\n",
        "# Read train, validation, test data\n",
        "raw_english_train = read_data(english_train_path)\n",
        "raw_chinese_train = read_data(chinese_train_path)\n",
        "raw_english_validation = read_data(english_validation_path)\n",
        "raw_chinese_validation = read_data(chinese_validation_path)\n",
        "raw_english_test = read_data(english_test_path)\n",
        "raw_chinese_test = read_data(chinese_test_path)\n",
        "\n",
        "# read scores for train and validation dataset \n",
        "score_train = read_data(scores_train_path)\n",
        "score_validation = read_data(scores_validation_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej1vYxsTFdH3",
        "colab_type": "text"
      },
      "source": [
        "## Sentence Embedding - BERT - large models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4s48XidZa2r",
        "colab_type": "text"
      },
      "source": [
        "Download and Import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXFF_aTdXT9_",
        "colab_type": "code",
        "outputId": "4b422481-f989-48eb-fbd9-7de4151637bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "!pip install bert-serving-server # server\n",
        "!pip install bert-serving-client # client, independent of 'bert-serving-server'\n",
        "from bert_serving.client import BertClient"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-server\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 25.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.17.5)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.12.0)\n",
            "Collecting pyzmq>=17.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/fa/e6e10410f01b03d10ab0705717d1246f63cdbbc0676140c78f0f757db332/pyzmq-19.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.1.0)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=a683aeeb969a3064f6c1e631bea0fa9755dcf1d61ffab6a911d0bb26d879aa9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, pyzmq, bert-serving-server\n",
            "  Found existing installation: pyzmq 17.0.0\n",
            "    Uninstalling pyzmq-17.0.0:\n",
            "      Successfully uninstalled pyzmq-17.0.0\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 pyzmq-19.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (19.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.17.5)\n",
            "Installing collected packages: bert-serving-client\n",
            "Successfully installed bert-serving-client-1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOlpbI8jec1x",
        "colab_type": "text"
      },
      "source": [
        "##### English Model \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvlLyD_Xq_6",
        "colab_type": "text"
      },
      "source": [
        "Large model:\n",
        "\n",
        "(24-layer, 1024-hidden, 16-heads, 340M parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9eqj2NNl7tO",
        "colab_type": "code",
        "outputId": "17ce74e7-712d-4335-cd3d-6e26227705fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# download pretrained BERT model wwm_cased_L-24_H-1024_A-16 (Whole Word Masking)\n",
        "!wget https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip\n",
        "!unzip wwm_cased_L-24_H-1024_A-16.zip\n",
        "en_model = \"wwm_cased_L-24_H-1024_A-16\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-28 14:51:41--  https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1242589256 (1.2G) [application/zip]\n",
            "Saving to: ‘wwm_cased_L-24_H-1024_A-16.zip’\n",
            "\n",
            "wwm_cased_L-24_H-10 100%[===================>]   1.16G  38.1MB/s    in 28s     \n",
            "\n",
            "2020-02-28 14:52:09 (42.2 MB/s) - ‘wwm_cased_L-24_H-1024_A-16.zip’ saved [1242589256/1242589256]\n",
            "\n",
            "Archive:  wwm_cased_L-24_H-1024_A-16.zip\n",
            "   creating: wwm_cased_L-24_H-1024_A-16/\n",
            "  inflating: wwm_cased_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
            "  inflating: wwm_cased_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: wwm_cased_L-24_H-1024_A-16/vocab.txt  \n",
            "  inflating: wwm_cased_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
            "  inflating: wwm_cased_L-24_H-1024_A-16/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84-B1qTePO3T",
        "colab_type": "text"
      },
      "source": [
        "Obtain English results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1XdIUpXPOd4",
        "colab_type": "code",
        "outputId": "edc3714e-6591-45b3-fe20-41a8c82e611f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# start server\n",
        "!nohup bert-serving-start -model_dir=./{en_model} > out.file 2>&1 &\n",
        "# open client\n",
        "bc_en = BertClient()\n",
        "# encode English raw corpus\n",
        "english_train_embeddings = bc_en.encode(raw_english_train)\n",
        "english_val_embeddings = bc_en.encode(raw_english_validation)\n",
        "english_test_embeddings = bc_en.encode(raw_english_test)\n",
        "# close client\n",
        "bc_en.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
            "here is what you can do:\n",
            "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
            "- or, start a new server with a larger \"max_seq_len\"\n",
            "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr65cIehPTzW",
        "colab_type": "text"
      },
      "source": [
        "Save English results:\n",
        "\n",
        "We save results before we manually shut down the server."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYy7EQ__PY4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save English embedding results to csv files\n",
        "pd_english_train = pd.DataFrame(english_train_embeddings)\n",
        "pd_english_train.to_csv('english_train_berteb.csv', index=False)\n",
        "\n",
        "pd_english_dev = pd.DataFrame(english_val_embeddings)\n",
        "pd_english_dev.to_csv('english_dev_berteb.csv', index=False)\n",
        "\n",
        "pd_english_test = pd.DataFrame(english_test_embeddings)\n",
        "pd_english_test.to_csv('english_test_berteb.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SltdSv8nPbyD",
        "colab_type": "text"
      },
      "source": [
        "Read English results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Vl0p06PcNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read English embedding results from csv files\n",
        "english_train_embeddings = pd.read_csv('english_train_berteb.csv')\n",
        "english_train_embeddings = english_train_embeddings.values\n",
        "\n",
        "english_val_embeddings = pd.read_csv('english_dev_berteb.csv')\n",
        "english_val_embeddings = english_val_embeddings.values\n",
        "\n",
        "english_test_embeddings = pd.read_csv('english_test_berteb.csv')\n",
        "english_test_embeddings = english_test_embeddings.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcXJKUnKe6uf",
        "colab_type": "text"
      },
      "source": [
        "##### Chinese Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMgm28r-X59e",
        "colab_type": "text"
      },
      "source": [
        "Large model:\n",
        "\n",
        "(24-layer, 1024-hidden, 16-heads, 340M parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwYKkTRUmBC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "65fbdf94-da49-4387-f52b-0bb3ffe1d430"
      },
      "source": [
        "# download pretrained BERT model chinese_roberta_wwm_large_ext_L-24_H-1024_A-16 (Whole Word Masking)\n",
        "!wget https://storage.googleapis.com/chineseglue/pretrain_models/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip\n",
        "!unzip chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip -d chinese_roberta_wwm_large_ext_L-24_H-1024_A-16\n",
        "ch_model = \"chinese_roberta_wwm_large_ext_L-24_H-1024_A-16\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-28 15:45:16--  https://storage.googleapis.com/chineseglue/pretrain_models/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c0b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1213043734 (1.1G) [application/zip]\n",
            "Saving to: ‘chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip’\n",
            "\n",
            "chinese_roberta_wwm 100%[===================>]   1.13G  85.3MB/s    in 15s     \n",
            "\n",
            "2020-02-28 15:45:32 (75.7 MB/s) - ‘chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip’ saved [1213043734/1213043734]\n",
            "\n",
            "Archive:  chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip\n",
            "  inflating: chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_config.json  \n",
            "  inflating: chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt.index  \n",
            "  inflating: chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/bert_model.ckpt.meta  \n",
            "  inflating: chinese_roberta_wwm_large_ext_L-24_H-1024_A-16/vocab.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgAS_pxEJbup",
        "colab_type": "text"
      },
      "source": [
        "Obtain Chinese results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM50ycj1H_C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "ce5e6e09-4d3e-4a36-c57a-5191192b45bb"
      },
      "source": [
        "# start server\n",
        "!nohup bert-serving-start -model_dir=./{ch_model} > out.file 2>&1 &\n",
        "# open client\n",
        "bc_ch = BertClient()\n",
        "# encode Chinese raw corpus\n",
        "chninese_train_embeddings = bc_ch.encode(raw_chinese_train)\n",
        "chinese_val_embeddings = bc_ch.encode(raw_chinese_validation)\n",
        "chinese_test_embeddings = bc_ch.encode(raw_chinese_test)\n",
        "# close client\n",
        "bc_ch.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
            "here is what you can do:\n",
            "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
            "- or, start a new server with a larger \"max_seq_len\"\n",
            "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z0rLZSUZLjA",
        "colab_type": "text"
      },
      "source": [
        "#### Concatenate vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tLS7vjqXd_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate vectors\n",
        "sentence_embeddings_train = []\n",
        "sentence_embeddings_val = []    \n",
        "sentence_embeddings_test = []\n",
        "\n",
        "# Concatenate train vectors\n",
        "for i in range(len(english_train_embeddings)):\n",
        "    english = list(english_train_embeddings[i])\n",
        "    chinese = list(chninese_train_embeddings[i])\n",
        "    english.extend(chinese)\n",
        "    sentence_embeddings_train.append(english)\n",
        "\n",
        "# Concatenate validation vectors\n",
        "for i in range(len(english_val_embeddings)):\n",
        "    english = list(english_val_embeddings[i])\n",
        "    chinese = list(chinese_val_embeddings[i])\n",
        "    english.extend(chinese)\n",
        "    sentence_embeddings_val.append(english)\n",
        "# Concatenate test vectors\n",
        "for i in range(len(english_test_embeddings)):\n",
        "    english = list(english_test_embeddings[i])\n",
        "    chinese = list(chinese_test_embeddings[i])\n",
        "    english.extend(chinese)\n",
        "    sentence_embeddings_test.append(english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRe8WNXyYoDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_embeddings_train = np.asarray(sentence_embeddings_train).astype(float)\n",
        "sentence_embeddings_val = np.asarray(sentence_embeddings_val).astype(float)\n",
        "sentence_embeddings_test = np.asarray(sentence_embeddings_test).astype(float)\n",
        "\n",
        "score_train = np.asarray(score_train).astype(float)\n",
        "score_validation = np.asarray(score_validation).astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxB7hNT7Fh5X",
        "colab_type": "text"
      },
      "source": [
        "## Model: SVR\n",
        "\n",
        "It achieves the best result when k is set as 'rbf' based on experiment (in the commented part)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8uqnvCJoimG",
        "colab_type": "code",
        "outputId": "ffcdddc0-2ea4-4c84-882c-00c0dd9c2046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    \"\"\"\n",
        "    Method to calculate the root mean squared error.\n",
        "\n",
        "    Args: \n",
        "        predictions: the prediction of the model.\n",
        "        targets: the ground truth.\n",
        "    \n",
        "    Returns:\n",
        "        The sentence vector.\n",
        "    \"\"\"\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
        "\n",
        "# Train and fit into the model.\n",
        "clf_t = SVR(kernel='rbf')\n",
        "clf_t.fit(sentence_embeddings_train, score_train)\n",
        "predictions = clf_t.predict(sentence_embeddings_val)\n",
        "pearson = pearsonr(score_validation, predictions)\n",
        "print(f'RMSE: {rmse(predictions,score_validation)} Pearson {pearson[0]}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.8533648151501044 Pearson 0.447425094596136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkGsRC0WP8oo",
        "colab_type": "text"
      },
      "source": [
        "Save test results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKI4CXSP-rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    \"\"\"\n",
        "    Method to write scores to a file.\n",
        "\n",
        "    Args: \n",
        "        method_name: the name of the method.\n",
        "        scores: the predicted scores of the model.\n",
        "    \n",
        "    \"\"\"\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLxDvUP0QAMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ecaf0dc-52c5-46df-efdf-ee5a77ddb8e3"
      },
      "source": [
        "predictions_zh = clf_t.predict(sentence_embeddings_test)\n",
        "\n",
        "\n",
        "#EN_ZH\n",
        "\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"SVR\",predictions_zh)\n",
        "\n",
        "with ZipFile(\"en-zh_svr.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-zh_svr.zip')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}